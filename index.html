<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <!-- Meta tags for social media banners, these should be filled in appropriatly as they are your "business card" -->
  <!-- Replace the content tag with appropriate information -->
  <meta name="description" content="DESCRIPTION META TAG">
  <meta property="og:title" content="SOCIAL MEDIA TITLE TAG"/>
  <meta property="og:description" content="SOCIAL MEDIA DESCRIPTION TAG TAG"/>
  <meta property="og:url" content="URL OF THE WEBSITE"/>
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X630-->
  <meta property="og:image" content="static/image/your_banner_image.png" />
  <meta property="og:image:width" content="1200"/>
  <meta property="og:image:height" content="630"/>


  <meta name="twitter:title" content="TWITTER BANNER TITLE META TAG">
  <meta name="twitter:description" content="TWITTER BANNER DESCRIPTION META TAG">
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X600-->
  <meta name="twitter:image" content="static/images/your_twitter_banner_image.png">
  <meta name="twitter:card" content="summary_large_image">
  <!-- Keywords for your paper to be indexed by-->
  <meta name="keywords" content="KEYWORDS SHOULD BE PLACED HERE">
  <meta name="viewport" content="width=device-width, initial-scale=1">


  <title>FinMMR</title>
  <link rel="icon" type="image/jpeg" href="logo.png">
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
  rel="stylesheet">

  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
  href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script>
</head>
<body>


  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <div style="display: flex; align-items: center; justify-content: center; gap: 20px; margin-bottom: 20px;">
              <img src="logo.png" alt="FinMMR Logo" style="width: 80px; height: 80px; object-fit: contain;">
              <h1 class="title is-1 publication-title">FinMMR</h1>
            </div>
            <h2 class="title is-5">Make Financial Numerical Reasoning More Multimodal, Comprehensive, and Challenging</h2>
            <div class="is-size-5 publication-authors">
              <!-- Paper authors -->
              <span class="author-block">
                <a href="#" target="_blank">Zichen Tang</a>,</span>
                <span class="author-block">
                  <a href="#" target="_blank">Haihong E</a><sup>*</sup>,</span>
                <span class="author-block">
                  <a href="#" target="_blank">Jiacheng Liu</a>,</span>
                <span class="author-block">
                  <a href="#" target="_blank">Zhongjun Yang</a>,</span>
                <span class="author-block">
                  <a href="#" target="_blank">Rongjin Li</a>,</span>
                <span class="author-block">
                  <a href="#" target="_blank">Zihua Rong</a>,</span>
                <span class="author-block">
                  <a href="#" target="_blank">Haoyang He</a>,</span>
                <span class="author-block">
                  <a href="#" target="_blank">Zhuodi Hao</a>,</span>
                <span class="author-block">
                  <a href="#" target="_blank">Xinyang Hu</a>,</span>
                <span class="author-block">
                  <a href="#" target="_blank">Kun Ji</a>,</span>
                <span class="author-block">
                  <a href="#" target="_blank">Ziyan Ma</a>,</span>
                <span class="author-block">
                  <a href="#" target="_blank">Mengyuan Ji</a>,</span>
                <span class="author-block">
                  <a href="#" target="_blank">Jun Zhang</a>,</span>
                <span class="author-block">
                  <a href="#" target="_blank">Chenghao Ma</a>,</span>
                <span class="author-block">
                  <a href="#" target="_blank">Qianhe Zheng</a>,</span>
                <span class="author-block">
                  <a href="#" target="_blank">Yang Liu</a>,</span>
                <span class="author-block">
                  <a href="#" target="_blank">Yiling Huang</a>,</span>
                <span class="author-block">
                  <a href="#" target="_blank">Xinyi Hu</a>,</span>
                <span class="author-block">
                  <a href="#" target="_blank">Qing Huang</a>,</span>
                <span class="author-block">
                  <a href="#" target="_blank">Zijian Xie</a>,</span>
                <span class="author-block">
                  <a href="#" target="_blank">Shiyao Peng</a>
                </span>
                  </div>

                  <div class="is-size-5 publication-authors">
                    <span class="author-block">Beijing University of Posts and Telecommunications, Beijing, China<br><strong style="color: red;">ICCV 2025</strong></span>
                    <span class="eql-cntrb"><small><br><sup>*</sup>Corresponding author.</small></span>
                  </div>

                  <div class="column has-text-centered">
                    <div class="publication-links">
                         <!-- Arxiv PDF link -->
                      <span class="link-block">
                        <a href="#" target="_blank"
                        class="external-link button is-normal is-rounded is-dark">
                        <span class="icon">
                          <i class="fas fa-file-pdf"></i>
                        </span>
                        <span>Paper</span>
                      </a>
                    </span>

                  <!-- Github link -->
                  <span class="link-block">
                    <a href="https://github.com/BUPT-Reasoning-Lab/FinMMR" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code</span>
                  </a>
                </span>

                <!-- ArXiv abstract Link -->
                <span class="link-block">
                  <a href="#" target="_blank"
                  class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>

                  <!-- Dataset link -->
                  <span class="link-block">
                    <a href="#" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Dataset</span>
                  </a>
                </span>
              
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>


<!-- Image carousel -->
<section class="hero is-small">
  <div class="hero-body">
    <div class="container">
      <div id="results-carousel" class="carousel results-carousel">
       <div class="item">
        <!-- Your image here -->
        <img src="static/images/overview.png" alt="MY ALT TEXT"/>
        <h2 class="subtitle has-text-centered">
          Overview of the FinMMR dataset. FinMMR presents three challenges: (1) visual perception: 8.7K financial images of 14 categories; (2) knowledge reasoning: 4.3K financial questions of 14 subdomains; (3) numerical computation: multi-step precise calculation.
        </h2>
      </div>
      <div class="item">
        <!-- Your image here -->
        <img src="static/images/QA.png" alt="MY ALT TEXT"/>
        <h2 class="subtitle has-text-centered">
          Sampled FinMMR examples with two language (i.e. English and Chinese), rich images and different knowledge. The questions
and images need expert-level visual perception, knowledge reasoning and numerical computation.
        </h2>
      </div>
      <div class="item">
        <!-- Your image here -->
        <img src="static/images/3.png" alt="MY ALT TEXT"/>
        <h2 class="subtitle has-text-centered">
          The comparison between finance-related datasets. These datasets vary in size, domain coverage, modalities, and question type,
          with some focusing on text-only data while others include images. Each axis has scale labels with varying ranges to measure the number
          of questions from each dataset across different subdomains. In the Modalities, T means text input, I means Images input, P.I. means pure
          images input. In the Question Type, NUM means numerical answer, MC means multi-choice answer.
       </h2>
     </div>
     <div class="item">
      <!-- Your image here -->
      <img src="static/images/4.png" alt="MY ALT TEXT"/>
      <h2 class="subtitle has-text-centered">
        Results of different models using IO, CoT and PoT prompting methods on the test set of FinMMR. We use average Accuracy using
CoT prompting as the ranking indicator of model performance. The results underscore the superior performance of reasoning-enhanced
MLLM (i.e. Claude 3.7 Sonnet with 64K extended thinking) with PoT in complex multimodal numerical reasoning task.
      </h2>
    </div>
    <div class="item">
      <!-- Your image here -->
      <img src="static/images/5.png" alt="MY ALT TEXT"/>
      <h2 class="subtitle has-text-centered">
        Degradation of Qwen2.5-VL-72B on all subsets due to distractor images and improvement achieved by the filtering-reasoning
        pipeline on the medium validation set under PoT setting.
      </h2>
    </div>
    <div class="item">
      <!-- Your image here -->
      <img src="static/images/6.png" alt="MY ALT TEXT"/>
      <h2 class="subtitle has-text-centered">
        Improvements of different MLLMs with knowledge augmentation on the 1,160 problems of FinMMR under PoT setting.
      </h2>
    </div>
    <div class="item">
      <!-- Your image here -->
      <img src="static/images/7.png" alt="MY ALT TEXT"/>
      <h2 class="subtitle has-text-centered">
        Results of model combinations and individual models.
      </h2>
    </div>
  </div>
</div>
</div>
</section>
<!-- End image carousel -->


<!-- Paper abstract -->
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            We present <strong>FinMMR</strong>, a novel bilingual multimodal benchmark tailored to evaluate the reasoning
            capabilities of multimodal large language models (MLLMs) in financial numerical reasoning tasks. Compared to
            existing benchmarks, our work introduces <strong>three significant advancements</strong>.
          </p>
          <p>
            <strong>(1) Multimodality</strong>: We meticulously transform existing financial reasoning datasets, and construct novel questions from
            the latest Chinese financial research reports. The dataset
            comprises <strong>4.3K questions</strong> and <strong>8.7K images</strong> spanning <strong>14
            categories</strong>, including tables, bar charts, and ownership
            structure charts.
          </p>
          <p>
            <strong>(2) Comprehensiveness</strong>: FinMMR encompasses <strong>14 financial subdomains</strong>, including corporate
            finance, banking, and industry analysis, significantly exceeding existing benchmarks in financial domain knowledge
            breadth.
          </p>
          <p>
            <strong>(3) Challenge</strong>: Models are required to perform
            multi-step precise numerical reasoning by integrating financial knowledge with the understanding of complex financial
            images and text. The best-performing MLLM achieves only <strong>51.4%</strong> accuracy on Hard problems.
          </p>
          <p>
            We believe that FinMMR will drive advancements in enhancing the reasoning
            capabilities of MLLMs in real-world scenarios.
          </p>
          
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End paper abstract -->


<!-- Paper poster -->
<section class="hero is-small is-light">
  <div class="hero-body">
    <div class="container">
      <h2 class="title">Paper</h2>

      <iframe  src="static/pdfs/iccv.pdf" width="100%" height="550">
          </iframe>
        
      </div>
    </div>
  </section>
<!--End paper poster -->


<!--BibTex citation -->
  <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <h2 class="title">BibTeX</h2>
      <pre><code>BibTex Code Here</code></pre>
    </div>
</section>
<!--End BibTex citation -->


  <footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">

          <p>
            This page was built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank">Academic Project Page Template</a> which was adopted from the <a href="https://nerfies.github.io" target="_blank">Nerfies</a> project page.
            You are free to borrow the source code of this website, we just ask that you link back to this page in the footer. <br> This website is licensed under a <a rel="license"  href="http://creativecommons.org/licenses/by-sa/4.0/" target="_blank">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>

        </div>
      </div>
    </div>
  </div>
</footer>

<!-- Statcounter tracking code -->
  
<!-- You can add a tracker to track page visits by creating an account at statcounter.com -->

    <!-- End of Statcounter Code -->

  </body>
  </html>
